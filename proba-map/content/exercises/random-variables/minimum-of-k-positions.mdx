---
id: "minimum-of-k-positions"
title: "Minimum of k Positions"
difficulty: "Medium"
patterns: ["random-variables"]
tags:
    [
        "probability",
        "expectation",
        "combinatorics",
        "minimum",
        "hockey-stick-identity",
    ]
---

## Exercise

We choose $k$ distinct positions uniformly at random from the set $\{1, 2, \dots, n\}$.

Let:

$$
M = \min\{X_1, \dots, X_k\}
$$

be the minimum of the chosen positions.

Calculate the expectation $\mathbb{E}[M]$.

## Hint

Find the probability $P(M > m)$ by counting how many ways all $k$ positions can be chosen from $\{m+1, \dots, n\}$.

## Hint

Use the formula $\mathbb{E}[M] = \sum_{m=0}^{n-1} P(M > m)$ and apply the hockey-stick identity to simplify the sum.

## Solution

We choose $k$ distinct positions uniformly at random from $\{1, 2, \dots, n\}$.

Let $M = \min\{X_1, \dots, X_k\}$ be their minimum.

**1. Distribution of $M$.**

We have:

$$
P(M > m) = P(\text{all } k \text{ elements are in } \{m+1, \dots, n\})
$$

The number of ways to choose $k$ elements from $\{m+1, \dots, n\}$ is $\binom{n-m}{k}$.

The total number of $k$-subsets in $\{1, \dots, n\}$ is $\binom{n}{k}$.

Therefore:

$$
P(M > m) = \frac{\binom{n-m}{k}}{\binom{n}{k}}, \qquad m = 0, 1, \dots, n-k
$$

**2. Expectation formula.**

Using the general formula:

$$
\mathbb{E}[M] = \sum_{m=0}^{n-1} P(M > m)
$$

Thus:

$$
\mathbb{E}[M] = \sum_{m=0}^{n-1} \frac{\binom{n-m}{k}}{\binom{n}{k}}
$$

**3. Change of index.**

Let $j = n - m$. Then $m = 0 \Rightarrow j = n$, and $m = n-1 \Rightarrow j = 1$.

Therefore:

$$
\mathbb{E}[M] = \frac{1}{\binom{n}{k}} \sum_{j=1}^{n} \binom{j}{k}
$$

**4. Combinatorial identity.**

We use the **hockey-stick identity**:

$$
\sum_{j=k}^{n} \binom{j}{k} = \binom{n+1}{k+1}
$$

Therefore:

$$
\mathbb{E}[M] = \frac{\binom{n+1}{k+1}}{\binom{n}{k}}
$$

**5. Simplification.**

We have:

$$
\frac{\binom{n+1}{k+1}}{\binom{n}{k}} = \frac{\frac{(n+1)!}{(k+1)!(n-k)!}}{\frac{n!}{k!(n-k)!}} = \frac{n+1}{k+1}
$$

Thus:

$$
\boxed{\mathbb{E}[M] = \frac{n+1}{k+1}}
$$
